# ONNX Explained

ONNX (Open Neural Network Exchange) is an open-source format for representing machine learning models. It’s the backbone of WhiteLightning.ai’s portability, letting our distilled models—brewed in TensorFlow, PyTorch, or Scikit-learn—run on diverse platforms without a second fermentation. Think of it as the mason jar for our moonshine AI: sturdy, universal, and ready to pour anywhere.

- **Interoperability**: Sip the same model in Python, JavaScript, C++, Rust, and beyond—no recipe tweaks needed.
- **Performance**: Optimized for a quick kick on CPUs, GPUs, and edge devices, no matter the still.
- **Compactness**: Small file sizes mean you can stash it in your pocket—perfect for deployment from cloud to creek.

With ONNX, WhiteLightning.ai delivers AI that’s as versatile as moonshine in a jar, ready to shine wherever you take it.

# Resources
**ONNX Runtime Docs:** github.com/microsoft/onnxruntime - Official guide for all platforms.

**WhiteLightning.ai Repo:** Check our GitHub for full examples and preprocessing code.

**ONNX Tutorials:** onnx.ai - Learn the nuts and bolts of ONNX.

Pour your WhiteLightning.ai model into any of these, and you’ll be sipping predictions in no time!

