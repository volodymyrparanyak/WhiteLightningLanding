# Overview

WhiteLightning.ai is a playground and toolkit for distilling the power of large language models (LLMs) into compact, efficient binary classifiers. Using knowledge distillation, we generate synthetic training data from user-defined problems and train lightweight ONNX models that run anywhere—from your browser to edge devices. Think of it as moonshine AI: potent, portable, and fast. We take the heavy barrels of LLM wisdom, ferment them with clever prompts, and bottle them into models that pack a punch without the hangover of complexity.

## Why WhiteLightning.ai?

We’re not just brewing another AI tool—we’re crafting a distilled experience that’s smooth to sip and easy to share. Whether you’re classifying spam, sentiment, or your grandma’s secret recipes, WhiteLightning.ai turns big AI into something you can carry in your pocket.

### Key Features
- **Distillation Magic**: Leverage LLMs to create synthetic datasets tailored to your binary classification needs.
- **ONNX Everywhere**: Export models to ONNX for seamless deployment on Python, JavaScript, C, C++, Rust, and beyond.
- **Lightweight & Fast**: Models designed to run on edge devices, browsers, or servers without breaking a sweat.
- **User-Friendly**: Define your problem with simple prompts, and let us handle the heavy lifting.

## Pros and Cons

Like any good moonshine, WhiteLightning.ai has its kick and its quirks. Here’s the rundown:

### Pros
- **Potent Performance**: High accuracy from distilled models, rivaling bulkier LLMs for binary tasks.
- **Portable as a Flask**: ONNX models run anywhere—your phone, a Raspberry Pi, or even a still in the woods.
- **Quick to Brew**: Fast training and deployment, no PhD in AI required.
- **Smooth Sip**: Minimal resource usage means no headaches from bloated frameworks.

### Cons
- **Binary Only**: We’re focused on yes/no problems—multiclass distillation is still aging in the barrel.
- **Prompt Craftsmanship**: Results depend on how well you stir your prompts—garbage in, garbage out.
- **No Fancy Garnish**: Simple classifiers, not full-blown LLMs; don’t expect poetry or chit-chat.

## Moonshine AI Jokes

- Why’d the LLM go to WhiteLightning.ai? It wanted to slim down and ditch the barrel!
- Our models are so fast, they’ll classify your text before the revenuers catch wind.
- Distilling AI is like making moonshine: a little heat, a lot of craft, and you’ve got something that’ll knock your socks off.

## What’s Cooking in the Still?

WhiteLightning.ai is just the first batch. We’re tinkering with more recipes—think multiclass classifiers, real-time distillation, and maybe a splash of explainability. Stick around; the next pour might just be your flavor.